{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMpfyVHOcY4lCDb8gqQn8bv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alberto2020china/Topic_Modelling/blob/main/1_ac_cluster%26topic_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1- Libraries and dependencies\n",
        "\n"
      ],
      "metadata": {
        "id": "ZxGMI-5k-wKq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMzZAeEXrKo8",
        "outputId": "23fe97eb-dd91-48a4-a080-876d3e20111e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (from imblearn) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (3.2.0)\n",
            "Installing collected packages: imblearn\n",
            "Successfully installed imblearn-0.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.5.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.2.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.58.1)\n",
            "Collecting pynndescent>=0.5 (from umap-learn)\n",
            "  Downloading pynndescent-0.5.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.66.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.41.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.2.0)\n",
            "Building wheels for collected packages: umap-learn\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.5-py3-none-any.whl size=86832 sha256=4e23a57129437f54139a1b81c95215815e1c3c1cc9e10b5ed73fa8e543724cda\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/70/07/428d2b58660a1a3b431db59b806a10da736612ebbc66c1bcc5\n",
            "Successfully built umap-learn\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.11 umap-learn-0.5.5\n",
            "Collecting hdbscan\n",
            "  Downloading hdbscan-0.8.33.tar.gz (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cython<3,>=0.27 (from hdbscan)\n",
            "  Using cached Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->hdbscan) (3.2.0)\n",
            "Building wheels for collected packages: hdbscan\n",
            "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.33-cp310-cp310-linux_x86_64.whl size=3039276 sha256=ceb8972941fdd7b840f5c97b1d558b2fdd1a844dae3e10d4f00488eae6c0af75\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/0b/3b/dc4f60b7cc455efaefb62883a7483e76f09d06ca81cf87d610\n",
            "Successfully built hdbscan\n",
            "Installing collected packages: cython, hdbscan\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 3.0.6\n",
            "    Uninstalling Cython-3.0.6:\n",
            "      Successfully uninstalled Cython-3.0.6\n",
            "Successfully installed cython-0.29.37 hdbscan-0.8.33\n"
          ]
        }
      ],
      "source": [
        "!pip install imblearn\n",
        "!pip install transformers\n",
        "!pip install umap-learn\n",
        "!pip install hdbscan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "768e1d92"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "#import contractions # I'm you'r etc\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer,CountVectorizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "from tqdm import tqdm # printing the status bar\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2-Import Data"
      ],
      "metadata": {
        "id": "z3ZqN1vmR5ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPGiMfFasD-P",
        "outputId": "e70b4c5b-34a1-4ebd-bdf6-ba1157b9b192"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Omdena/DataInn/complete_documents_metadata_summary.csv',encoding='windows-1252')"
      ],
      "metadata": {
        "id": "N5La6ZQBwdwP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "3Rowr9Qcyibz",
        "outputId": "dac17713-a6c4-4f4d-b152-2b935ed99dda"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Title  \\\n",
              "0   Action Coalition on Innovation and Technology ...   \n",
              "1                         Chinese Academy of Sciences   \n",
              "2   International Federation of Library Associatio...   \n",
              "3                Global Partners Digital input to GDC   \n",
              "4                   International Chamber of Commerce   \n",
              "5               Alliance for Universal Digital Rights   \n",
              "6   Equity 2030: Building Equitable Future - Submi...   \n",
              "7   GDC Stimson Center: Rethinking Global Cooperation   \n",
              "8                             GDC submission EuroSSIG   \n",
              "9                                       GDC-input JBI   \n",
              "10               Global Partners Digital input to GDC   \n",
              "11                  International Chamber of Commerce   \n",
              "12              Alliance for Universal Digital Rights   \n",
              "13  Rethinking Global Cooperation: Three New Frame...   \n",
              "14  Binary¡¯s Submission to the Global Digital Com...   \n",
              "15               Inputs to the Global Digital Compact   \n",
              "\n",
              "                                      Organization  \\\n",
              "0                                          Various   \n",
              "1                      Chinese Academy of Sciences   \n",
              "2                                             IFLA   \n",
              "3                          Global Partners Digital   \n",
              "4                International Chamber of Commerce   \n",
              "5            Alliance for Universal Digital Rights   \n",
              "6                                      Equity 2030   \n",
              "7                                   Stimson Center   \n",
              "8                                         EuroSSIG   \n",
              "9                                              JBI   \n",
              "10                         Global Partners Digital   \n",
              "11               International Chamber of Commerce   \n",
              "12           Alliance for Universal Digital Rights   \n",
              "13                   Stimson Center and Doha Forum   \n",
              "14                                          Binary   \n",
              "15  Brazilian Internet Steering Committee (CGI.br)   \n",
              "\n",
              "                                             Keywords  \\\n",
              "0       Gender Equality, Technology, Inclusive Design   \n",
              "1                      Big Data, Sustainability, CBAS   \n",
              "2                 Libraries, Information Access, SDGs   \n",
              "3    Digital Inclusion, Human Rights, Internet Policy   \n",
              "4   Internet Connectivity, AI Regulation, Human Ri...   \n",
              "5     Digital Technologies, Universal Access, Privacy   \n",
              "6                Gender Equity, Technology, Inclusion   \n",
              "7      Global Cooperation, Digital Policy, Innovation   \n",
              "8        Internet Governance, Education, Stakeholders   \n",
              "9         Bioethics, Digital Ethics, Global Standards   \n",
              "10                Digital Rights, Internet Governance   \n",
              "11                    Digital Future, Data Protection   \n",
              "12                       Digital Rights, Human Rights   \n",
              "13  Global Policy, Future Generations, Digital Com...   \n",
              "14     Spyware, Human Rights, Surveillance Technology   \n",
              "15  Internet Access, Data Protection, Human Rights...   \n",
              "\n",
              "                                              Summary  \n",
              "0   Advocates for integrating gender equality in d...  \n",
              "1   Discusses the role of big data in sustainable ...  \n",
              "2   Emphasizes libraries' role in achieving the Su...  \n",
              "3   Addresses digital rights and internet governan...  \n",
              "4   Focuses on the Global Digital Compact, coverin...  \n",
              "5   Advocates for digital rights as human rights, ...  \n",
              "6   Discusses strategies to achieve gender equity ...  \n",
              "7   Explores innovative approaches to global coope...  \n",
              "8   Discusses the importance of internet governanc...  \n",
              "9   Focuses on bioethics in the digital age, discu...  \n",
              "10  Addresses the importance of digital rights and...  \n",
              "11  Focuses on principles for a connected digital ...  \n",
              "12  Advocates for digital rights as human rights, ...  \n",
              "13  Explores challenges and solutions for global c...  \n",
              "14  Focuses on the use of spyware and its human ri...  \n",
              "15  Outlines Brazil's contributions to the Global ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-03d89cc9-3224-405d-83da-8ae99bde46fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Organization</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Action Coalition on Innovation and Technology ...</td>\n",
              "      <td>Various</td>\n",
              "      <td>Gender Equality, Technology, Inclusive Design</td>\n",
              "      <td>Advocates for integrating gender equality in d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Chinese Academy of Sciences</td>\n",
              "      <td>Chinese Academy of Sciences</td>\n",
              "      <td>Big Data, Sustainability, CBAS</td>\n",
              "      <td>Discusses the role of big data in sustainable ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>International Federation of Library Associatio...</td>\n",
              "      <td>IFLA</td>\n",
              "      <td>Libraries, Information Access, SDGs</td>\n",
              "      <td>Emphasizes libraries' role in achieving the Su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Global Partners Digital input to GDC</td>\n",
              "      <td>Global Partners Digital</td>\n",
              "      <td>Digital Inclusion, Human Rights, Internet Policy</td>\n",
              "      <td>Addresses digital rights and internet governan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>International Chamber of Commerce</td>\n",
              "      <td>International Chamber of Commerce</td>\n",
              "      <td>Internet Connectivity, AI Regulation, Human Ri...</td>\n",
              "      <td>Focuses on the Global Digital Compact, coverin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Alliance for Universal Digital Rights</td>\n",
              "      <td>Alliance for Universal Digital Rights</td>\n",
              "      <td>Digital Technologies, Universal Access, Privacy</td>\n",
              "      <td>Advocates for digital rights as human rights, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Equity 2030: Building Equitable Future - Submi...</td>\n",
              "      <td>Equity 2030</td>\n",
              "      <td>Gender Equity, Technology, Inclusion</td>\n",
              "      <td>Discusses strategies to achieve gender equity ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GDC Stimson Center: Rethinking Global Cooperation</td>\n",
              "      <td>Stimson Center</td>\n",
              "      <td>Global Cooperation, Digital Policy, Innovation</td>\n",
              "      <td>Explores innovative approaches to global coope...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>GDC submission EuroSSIG</td>\n",
              "      <td>EuroSSIG</td>\n",
              "      <td>Internet Governance, Education, Stakeholders</td>\n",
              "      <td>Discusses the importance of internet governanc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>GDC-input JBI</td>\n",
              "      <td>JBI</td>\n",
              "      <td>Bioethics, Digital Ethics, Global Standards</td>\n",
              "      <td>Focuses on bioethics in the digital age, discu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Global Partners Digital input to GDC</td>\n",
              "      <td>Global Partners Digital</td>\n",
              "      <td>Digital Rights, Internet Governance</td>\n",
              "      <td>Addresses the importance of digital rights and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>International Chamber of Commerce</td>\n",
              "      <td>International Chamber of Commerce</td>\n",
              "      <td>Digital Future, Data Protection</td>\n",
              "      <td>Focuses on principles for a connected digital ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Alliance for Universal Digital Rights</td>\n",
              "      <td>Alliance for Universal Digital Rights</td>\n",
              "      <td>Digital Rights, Human Rights</td>\n",
              "      <td>Advocates for digital rights as human rights, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Rethinking Global Cooperation: Three New Frame...</td>\n",
              "      <td>Stimson Center and Doha Forum</td>\n",
              "      <td>Global Policy, Future Generations, Digital Com...</td>\n",
              "      <td>Explores challenges and solutions for global c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Binary¡¯s Submission to the Global Digital Com...</td>\n",
              "      <td>Binary</td>\n",
              "      <td>Spyware, Human Rights, Surveillance Technology</td>\n",
              "      <td>Focuses on the use of spyware and its human ri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Inputs to the Global Digital Compact</td>\n",
              "      <td>Brazilian Internet Steering Committee (CGI.br)</td>\n",
              "      <td>Internet Access, Data Protection, Human Rights...</td>\n",
              "      <td>Outlines Brazil's contributions to the Global ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03d89cc9-3224-405d-83da-8ae99bde46fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-03d89cc9-3224-405d-83da-8ae99bde46fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-03d89cc9-3224-405d-83da-8ae99bde46fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-53eed36e-c7ac-4f11-b42f-1851c11b7ef4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-53eed36e-c7ac-4f11-b42f-1851c11b7ef4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-53eed36e-c7ac-4f11-b42f-1851c11b7ef4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3-Preprocessing"
      ],
      "metadata": {
        "id": "y9YNq4ojR9Zv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BYBbOmrv4hdQ"
      },
      "outputs": [],
      "source": [
        "# https://gist.github.com/sebleier/554280\n",
        "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
        "# <br /><br /> ==> after the above steps, we are getting \"br br\"\n",
        "# we are including them into stop words list\n",
        "# instead of <br /> if we have <br/> these tags would have revmoved in the 1st step\n",
        "\n",
        "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "81f60e19"
      },
      "outputs": [],
      "source": [
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase\n",
        "\n",
        "def preprocess(corpus):\n",
        "    preprocessed = []\n",
        "    for sentance in tqdm(corpus):\n",
        "        #sentance = re.sub(r\"http+\", \"\", sentance)\n",
        "        sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
        "        sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
        "        sentance = decontracted(sentance)\n",
        "        sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
        "        sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
        "        sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
        "        preprocessed.append(sentance.strip())\n",
        "\n",
        "    return preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Summary_transformed\"] = preprocess(df['Summary'].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HokdDtHWsFee",
        "outputId": "d44a181a-5697-4c61-f453-dd9fe8072767"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:00<00:00, 1033.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4-Clustering"
      ],
      "metadata": {
        "id": "I8qOcWUySDZU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Hm1vq3UZ988g"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import umap\n",
        "import hdbscan\n",
        "import pandas as pd\n",
        "\n",
        "def preprocess_text(text):\n",
        "    preprocessed_text = str(text).lower()  # Basic preprocessing, modify as needed\n",
        "    return preprocessed_text\n",
        "\n",
        "def process_batch(tokenizer, model, jobs):\n",
        "    tokenized_articles = [tokenizer.encode_plus(\n",
        "        preprocess_text(job),\n",
        "        add_special_tokens=True,\n",
        "        max_length=512,  # Define your desired max length\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,  # Include attention mask\n",
        "        return_tensors='pt'\n",
        "    ) for job in jobs]\n",
        "\n",
        "    input_ids = torch.cat([article['input_ids'] for article in tokenized_articles], dim=0)\n",
        "    attention_masks = torch.cat([article['attention_mask'] for article in tokenized_articles], dim=0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_masks)\n",
        "        embeddings = outputs[0][:, 0, :].cpu().numpy()  # Extract the [CLS] token embeddings, move to CPU\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "def clustering(df, variable,batch_size=34):\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "    model.eval()\n",
        "\n",
        "    embeddings_list = []\n",
        "    for i in range(0, len(df), batch_size):\n",
        "        print(i)\n",
        "        batch_articles = df[variable].iloc[i:i+batch_size].tolist()\n",
        "        batch_embeddings = process_batch(tokenizer, model, batch_articles)\n",
        "        embeddings_list.append(batch_embeddings)\n",
        "\n",
        "    embeddings = np.concatenate(embeddings_list, axis=0) if embeddings_list else np.array([])\n",
        "\n",
        "    if embeddings.size > 0:\n",
        "        reducer = umap.UMAP(n_components=5)\n",
        "        reduced_embeddings = reducer.fit_transform(embeddings)\n",
        "\n",
        "        clusterer = hdbscan.HDBSCAN(min_cluster_size=3)\n",
        "        cluster_labels = clusterer.fit_predict(reduced_embeddings)\n",
        "\n",
        "        df['cluster_type'] = cluster_labels\n",
        "        df['embeddings'] = embeddings.tolist()\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clustering(df,\"Summary_transformed\")"
      ],
      "metadata": {
        "id": "NZPWN8Nizy5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Summary_transformed\"] = df[\"Summary_transformed\"].astype(str)\n",
        "print('clustering agg',df['cluster_type'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVb-Lb2x0buW",
        "outputId": "57410fe2-956e-4ea9-da1c-86edbebb4f2b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clustering agg  1    9\n",
            " 0    5\n",
            "-1    2\n",
            "Name: cluster_type, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5-Topic Modelling"
      ],
      "metadata": {
        "id": "MgJRshIFSJO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs_per_topic_agg = df.groupby(['cluster_type'], as_index = False).agg({\"Summary_transformed\": ' '.join})"
      ],
      "metadata": {
        "id": "mtI66nH81oa3"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_per_topic_agg"
      ],
      "metadata": {
        "id": "ATwF2HeE3nNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
        "    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n",
        "    t = count.transform(documents).toarray()\n",
        "    w = t.sum(axis=1)\n",
        "    tf = np.divide(t.T, w)\n",
        "    sum_t = t.sum(axis=0)\n",
        "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
        "    tf_idf = np.multiply(tf, idf)\n",
        "\n",
        "    return tf_idf, count"
      ],
      "metadata": {
        "id": "pTj3_e0Q2eb_"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "yZnyQFrUI_Sk"
      },
      "outputs": [],
      "source": [
        "def extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=10):\n",
        "    words = count.get_feature_names_out()\n",
        "    labels = list(docs_per_topic.cluster_type)\n",
        "    tf_idf_transposed = tf_idf.T\n",
        "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
        "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
        "    return top_n_words\n",
        "\n",
        "def extract_topic_sizes(df):\n",
        "    topic_sizes = (df.groupby(['cluster_type'])\n",
        "                     .text\n",
        "                     .count()\n",
        "                     .reset_index()\n",
        "                     .rename({\"Topic\": \"cluster\", \"Summary_transformed\": \"Size\"}, axis='columns')\n",
        "                     .sort_values(\"Size\", ascending=False))\n",
        "    return topic_sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "RF9nsjiOJFeo"
      },
      "outputs": [],
      "source": [
        "tf_idf_agg, count_agg = c_tf_idf(docs_per_topic_agg.Summary_transformed.values, m=len(df))\n",
        "top_n_words_agg = extract_top_n_words_per_topic(tf_idf_agg, count_agg, docs_per_topic_agg, n=10)\n",
        "#topic_sizes_agg = extract_topic_sizes(df_train); topic_sizes_agg.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6-Semantic Interpretation per Cluster"
      ],
      "metadata": {
        "id": "xGkBxrYmSOIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_n_words_agg[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMOo6DG74Ri3",
        "outputId": "95c42c38-770d-4aa7-d6af-4676f6fba392"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('stakeholders', 0.09241962407465937),\n",
              " ('education', 0.09241962407465937),\n",
              " ('governance', 0.09241962407465937),\n",
              " ('informed', 0.09241962407465937),\n",
              " ('addresses', 0.06931471805599453),\n",
              " ('inclusion', 0.06931471805599453),\n",
              " ('related', 0.06931471805599453),\n",
              " ('world', 0.05579921445238905),\n",
              " ('focusing', 0.05579921445238905),\n",
              " ('policy', 0.05579921445238905)]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n_words_agg[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQWz8Fp44SeN",
        "outputId": "91a0f57c-1239-4b23-f214-e88be78ab435"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('advocating', 0.05134423559703298),\n",
              " ('strategies', 0.04133275144621411),\n",
              " ('role', 0.04133275144621411),\n",
              " ('access', 0.03632700937080467),\n",
              " ('rethinking', 0.034229490398021985),\n",
              " ('inequalities', 0.034229490398021985),\n",
              " ('information', 0.034229490398021985),\n",
              " ('innovative', 0.034229490398021985),\n",
              " ('learning', 0.034229490398021985),\n",
              " ('libraries', 0.034229490398021985)]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n_words_agg[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r88z87eX4TWg",
        "outputId": "5c2a3b7d-19a2-4822-cde0-21db734c00b4"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('highlights', 0.02166084939249829),\n",
              " ('like', 0.019616911330918026),\n",
              " ('spyware', 0.019616911330918026),\n",
              " ('future', 0.019616911330918026),\n",
              " ('document', 0.019616911330918026),\n",
              " ('importance', 0.018174231403213763),\n",
              " ('development', 0.018174231403213763),\n",
              " ('focuses', 0.016245637044373717),\n",
              " ('ethical', 0.016245637044373717),\n",
              " ('principles', 0.016245637044373717)]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cluster -1: Education and Governance\n",
        "\n",
        "This cluster seems to revolve around themes of education, governance, and stakeholder engagement. The presence of words like 'stakeholders', 'education', 'governance', and 'informed' suggests a focus on the need for educating stakeholders about governance. The cluster likely represents documents that address the importance of informed participation in governance and the inclusion of diverse voices in policy-making processes.\n",
        "\n",
        "Cluster 0: Advocacy and Information Access\n",
        "\n",
        "The keywords 'advocating', 'strategies', 'role', 'access', 'learning', and 'libraries' point towards advocacy for information access and learning. The terms 'rethinking' and 'innovative' imply a call for new strategies or methods, potentially in the context of library services or educational resources. This cluster is likely about documents that discuss the strategic role of organizations in providing access to information and promoting continuous learning, with an emphasis on innovation and addressing inequalities.\n",
        "\n",
        "Cluster 1: Technology Ethics and Regulation\n",
        "\n",
        "With words such as 'spyware', 'future', 'ethical', and 'principles', this cluster seems focused on the ethical implications of technology and its future development. The term 'highlights' suggests these documents draw attention to specific issues like spyware and the need for ethical principles in technology development and use. 'Importance' and 'document' together indicate these might be official documents or position papers outlining the significance of ethical considerations in tech policy and development."
      ],
      "metadata": {
        "id": "lIF-2RpW44ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "oXlkj8Be5Gbh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}